
import numpy as np
import random
import cvxpy as cvx
import pandas as pd
from scipy.stats import norm


def SimulateData(N_c, N_t, mu, Sigma, l, u, Gamma):

	"""
	Function that generates random control and treated units.
	Each treated unit is generated by:
		X_t = w' X_c + epsilon,
	where
		X_c ~ N(mu, Sigma), epsilon ~ N(0, Gamma)
	Args:
		N_c = Number of control units
		N_t = Number of treated units
		mu = k-dimensional mean covariate value of control units
		Sigma = k-by-k covariance matrix of covariates of control units
		l = Minimum number of non-zero weights on the control units
		u = Maximum number of non-zero weights on the control units
		Gamma = k-by-k covariance matrix of normal, zero-mean error term
	Returns:
		X_c = N_c-by-k matrix of generated control units
		X_t = N_t-by-k matrix of generated treated units
		W = N_t-by-N_c matrix of weights put on control units
	"""

	# covariates of controls
	X_c = np.random.multivariate_normal(mean=mu, cov=Sigma, size=N_c)

	W = np.zeros(shape=(N_t, N_c))  # matrix of weights

	# number of non-zero weights for each X_t, generated randomly
	n = np.random.randint(low=l, high=u, size=N_t)

	for i in xrange(N_t):

		# controls that get non-zero weights
		random_index = random.sample(xrange(N_c), n[i])

		# generate weights, then standardize to sum to 1
		non_standardized = np.random.uniform(size=n[i])

		W[i, random_index] = non_standardized / non_standardized.sum()

	k = len(mu)  # generate X_t below
	X_t = np.dot(W, X_c) + np.random.multivariate_normal(mean=np.zeros(k), cov=Gamma,
	                                                     size=N_t)

	return X_c, X_t, W


def SimulateData2(delta, beta, theta, mu, Sigma, Gamma, N, return_counterfactual=False):

	"""
	Function that generates data according to a simple linear model.
	The counterfactual outcomes are generated by:
		Y_0 = X*beta + epsilon_0,
		Y_1 = delta + X*(beta+theta) + epsilon_1,
	where
		X ~ N(mu, Sigma), epsilon ~ N(0, Gamma).
	Selection is done according to the following propensity score function:
		P(D=1|X) = Phi(X*beta),
	where Phi is the standard normal CDF.
	Args:
		delta = Scalar. Constant treatment effect common to all units
		beta, theta, mu = k-dimensional parameter vectors
		Sigma = k-by-k covariance matrix for the covariates
		Gamma = 2-by-2 covariance matrix for the error terms
		N = Total sample size (control + treated units) to generate
		return_counterfactual = Boolean indicating whether to return vectors of
		                        counterfactual outcomes
	Returns:
		Y = N-dimensional array of observed outcomes
		D = N-dimensional array of treatment indicator; 1=treated, 0=control
		X = N-by-k matrix of covariates
		Y_0 = N-dimensional array of non-treated outcomes
		Y_1 = N-dimensional array of treated outcomes
	"""

	k = len(mu)

	X = np.random.multivariate_normal(mean=mu, cov=Sigma, size=N)
	epsilon = np.random.multivariate_normal(mean=np.zeros(2), cov=Gamma, size=N)

	Xbeta = np.dot(X, beta)

	Y_0 = Xbeta + epsilon[:, 0]
	Y_1 = delta + np.dot(X, beta+theta) + epsilon[:, 1]

	pscore = norm.cdf(Xbeta)
	# for each p in pscore, generate Bernoulli rv with success probability p
	D = np.array([np.random.binomial(1, p, size=1) for p in pscore]).flatten()

	Y = (1 - D) * Y_0 + D * Y_1  # compute observed outcome

	if return_counterfactual:
		return Y, D, X, Y_0, Y_1
	else:
		return Y, D, X


def UseSimulatedData2():

	k = 3
	delta = 3
	beta = np.ones(k)
	theta = np.ones(k)
	mu = np.zeros(k)
	Sigma = np.identity(k)
	Gamma = np.identity(2)
	N = 500

	Y, D, X, Y_0, Y_1 = SimulateData2(delta, beta, theta, mu, Sigma, Gamma, N, True)
	print 'Actual average treatment effect on the treated:', (Y_1[D==1]-Y_0[D==1]).mean()

	control = (D == 0)
	treated = (D == 1)

	W_hat = EstimateWeights(X[control], X[treated])

	ITE_hat, ATE_hat = TreatmentEffects(Y[control], Y[treated], W_hat)

	print 'Estimated average treatment effect on the treated:', ATE_hat


def EstimateWeights(X_c, X_t):

	"""
	Function that estimates synthetic control weights for each treated unit.
	For each treated unit, we find w that minimizes:
		|| w' X_c - X_t ||_2,
	subject to the weights being between 0 and 1, and that they sum to 1.
	Convex optimization problem solved by calling CVX.
	Args:
		X_c = N_c-by-k matrix of control units
		X_t = N_t-by-k matrix of treated units
	Returns:
		W_hat = N_t-by-N_c matrix of estimated weights
	"""

	N_c = len(X_c)
	if len(X_t.shape) == 1:  # check if input is 1D-array
		N_t = 1
	else:
		N_t = len(X_t)  # there has to be a more elegant way of doing this

	W_hat = np.zeros(shape=(N_t, N_c))  # matrix of weight estimates

	for i in xrange(N_t):

		# for each treated unit, call CVX to solve optimization problem
		w = cvx.Variable(N_c)
		objective = cvx.Minimize(cvx.sum_squares(X_c.T * w - X_t[i, ]))
		constraints = [cvx.sum_entries(w) == 1]
		prob = cvx.Problem(objective, constraints)
		min_value = prob.solve()

		# constraints = [0 <= w, w <= 1, cvx.sum_entries(w) == 1]
		# note: with Lalonde data, restricting 0 <= w <= 1 yields no
		#       solutions for some treated units

		W_hat[i, ] = w.value.getA1()  # convert to flattened array and store

	return W_hat


def TreatmentEffects(Y_c, Y_t, W):

	"""
	Function that estimates individual and average treatment effects
	via synthetic control method, using provided synthetic control weights.
	Args:
		Y_c = N_c-dimensional array of control unit outcomes
		Y_t = N_t-dimensional array of treated unit outcomes
		W = N_t-by-N_c matrix of synthetic control weights
	Returns:
		IndividualTE = N_t-dimensional array of estimated individual treatment effects
		ATE = scalar value of estaimted average treatment effect
	"""

	IndividualTE = Y_t - np.dot(W, Y_c)
	ATE = IndividualTE.mean()

	return IndividualTE, ATE


"""
Need to write a wrapper function here that looks like this.
This is what the user would actually call.

def SyntheticControl(data, some way to specify Y, X, and D variables):
	# data probably should be in Data.Frame format

	1) Define X_t, X_c, Y_t, Y_c based on given specification
	2) Call W_hat = EstimateWeights(X_c, X_t)
	3) Call ITE_hat, ATE_hat = TreatmentEffects(Y_c, Y_t, W_hat)
	4) Report results
"""


def UseLalondeData():  # need better name, documentation

	url = 'http://www.stanford.edu/~lwong1/data.csv'
	lalonde = pd.read_csv(url)  # read CSV data from url

	covariate_list = ['age', 'education', 'black', 'hispanic', 'married',
	                  'nodegree', 're74', 're75', 'u74', 'u75']
	treated = lalonde['treat'] == 1  # index of treated units
	control = lalonde['treat'] == 0  # index of control units

	# don't know how to not convert to array first
	X_t = np.array(lalonde[treated][covariate_list])
	X_c = np.array(lalonde[control][covariate_list])
	W_hat = EstimateWeights(X_c, X_t)

	Y_t = np.array(lalonde[treated]['re78'])
	Y_c = np.array(lalonde[control]['re78'])
	ITE_hat, ATE_hat = TreatmentEffects(Y_c, Y_t, W_hat)

	print "Using Lalonde's National Supported Work (NSW) experimental data"
	print 'Mean difference:', Y_t.mean() - Y_c.mean()
	print 'Estimated average treatment effect:', ATE_hat


def UseSimulatedData():

	N_c, N_t, k = 5, 3, 2  # set parameters
	mu, Sigma, l, u, Gamma = np.zeros(k), np.identity(k), 2, N_t, np.identity(k)
	
	X_c, X_t, W = SimulateData(N_c, N_t, mu, Sigma, l, u, Gamma)
	W_hat = EstimateWeights(X_c, X_t)

	print 'Actual weights:'
	print W
	print 'Estimated weights:'
	print W_hat

	# estimate weights using mean of X_t as the lone treated unit
	w = EstimateWeights(X_c, X_t.mean(axis=0))

	print 'Averaged weights:'
	print W_hat.mean(axis=0)
	print 'Estimated weights using averaged X_t:'
	print w.flatten()


def main():

	UseSimulatedData()


if __name__ == '__main__':
	main()
